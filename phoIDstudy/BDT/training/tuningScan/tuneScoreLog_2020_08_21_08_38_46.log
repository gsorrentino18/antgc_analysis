{'alpha': 850.0, 'colsample_bytree': 0.7669999999999999, 'eta': 0.042, 'gamma': 0.0, 'max_depth': 21, 'min_child_weight': 21.0, 'objective': 'binary:logistic', 'predictor': 'gpu_predictor', 'sampling_method': 'gradient_based', 'subsample': 0.5, 'tree_method': 'gpu_hist', 'bestValScore': 0.004045, 'bestIteration': 36, 'bestNtreeLimit': 37, 'theScore': 0.995955}
{
    "train": {
        "error": [
            0.002747,
            0.002404,
            0.002334,
            0.002317,
            0.002314,
            0.002263,
            0.002246,
            0.002256,
            0.002244,
            0.002264,
            0.002267,
            0.002255,
            0.002253,
            0.002255,
            0.002255,
            0.002255,
            0.00224,
            0.002226,
            0.002217,
            0.002203,
            0.002194,
            0.002193,
            0.00219,
            0.002179,
            0.00218,
            0.002171,
            0.002161,
            0.002151,
            0.002149,
            0.00214,
            0.002138,
            0.002141,
            0.002133,
            0.002122,
            0.002118,
            0.002113,
            0.002107,
            0.0021,
            0.002093,
            0.002087,
            0.002083,
            0.002078,
            0.002076,
            0.002068,
            0.002061,
            0.00206,
            0.002055,
            0.00205,
            0.002044,
            0.002043,
            0.002038,
            0.002034,
            0.002028,
            0.002025,
            0.002024,
            0.002022
        ]
    },
    "val": {
        "error": [
            0.00426,
            0.004209,
            0.004218,
            0.004223,
            0.004241,
            0.004184,
            0.004207,
            0.004204,
            0.004181,
            0.004178,
            0.004176,
            0.004148,
            0.004119,
            0.004135,
            0.004098,
            0.00412,
            0.004123,
            0.004098,
            0.004103,
            0.004105,
            0.004107,
            0.004097,
            0.004084,
            0.004076,
            0.004088,
            0.004089,
            0.004089,
            0.004079,
            0.004087,
            0.00408,
            0.00408,
            0.004079,
            0.004074,
            0.004067,
            0.004047,
            0.004052,
            0.004045,
            0.004048,
            0.004063,
            0.004077,
            0.004069,
            0.004065,
            0.004065,
            0.004075,
            0.004076,
            0.004076,
            0.004074,
            0.00407,
            0.004073,
            0.004077,
            0.004065,
            0.004058,
            0.004074,
            0.004077,
            0.00407,
            0.004082
        ]
    }
}{'alpha': 800.0, 'colsample_bytree': 0.944, 'eta': 0.045, 'gamma': 0.1, 'max_depth': 23, 'min_child_weight': 21.0, 'objective': 'binary:logistic', 'predictor': 'gpu_predictor', 'sampling_method': 'gradient_based', 'subsample': 0.5, 'tree_method': 'gpu_hist', 'bestValScore': 0.004122, 'bestIteration': 41, 'bestNtreeLimit': 42, 'theScore': 0.995878}
{
    "train": {
        "error": [
            0.002678,
            0.002448,
            0.00233,
            0.002258,
            0.002225,
            0.002185,
            0.002166,
            0.002161,
            0.002142,
            0.002143,
            0.002147,
            0.00214,
            0.002141,
            0.002133,
            0.002126,
            0.002112,
            0.002107,
            0.0021,
            0.002093,
            0.002084,
            0.002077,
            0.00207,
            0.002065,
            0.002055,
            0.002052,
            0.002048,
            0.00204,
            0.002037,
            0.002033,
            0.002029,
            0.002024,
            0.00202,
            0.002014,
            0.002008,
            0.002004,
            0.001999,
            0.001995,
            0.001988,
            0.001984,
            0.001978,
            0.001975,
            0.00197,
            0.001965,
            0.001961,
            0.001953,
            0.00195,
            0.001945,
            0.00194,
            0.001935,
            0.001933,
            0.001928,
            0.001923,
            0.001917,
            0.001913,
            0.001907,
            0.001902,
            0.001897,
            0.001891,
            0.001887,
            0.001883,
            0.001878
        ]
    },
    "val": {
        "error": [
            0.004222,
            0.004184,
            0.004212,
            0.004247,
            0.004253,
            0.004275,
            0.004271,
            0.00427,
            0.004264,
            0.004246,
            0.004258,
            0.004255,
            0.004234,
            0.004231,
            0.004221,
            0.004204,
            0.004187,
            0.004185,
            0.00418,
            0.004168,
            0.004153,
            0.004166,
            0.004151,
            0.004173,
            0.00419,
            0.004194,
            0.004201,
            0.004207,
            0.004207,
            0.00418,
            0.004188,
            0.004194,
            0.004185,
            0.004182,
            0.004174,
            0.004177,
            0.004159,
            0.004158,
            0.004154,
            0.004144,
            0.004131,
            0.004122,
            0.004124,
            0.004131,
            0.00413,
            0.004123,
            0.004129,
            0.004132,
            0.004134,
            0.004132,
            0.004126,
            0.004127,
            0.004129,
            0.004127,
            0.004129,
            0.004135,
            0.004127,
            0.004126,
            0.00413,
            0.004133,
            0.004142
        ]
    }
}{'alpha': 750.0, 'colsample_bytree': 0.649, 'eta': 0.049, 'gamma': 0.05, 'max_depth': 22, 'min_child_weight': 21.0, 'objective': 'binary:logistic', 'predictor': 'gpu_predictor', 'sampling_method': 'gradient_based', 'subsample': 0.7000000000000001, 'tree_method': 'gpu_hist', 'bestValScore': 0.00406, 'bestIteration': 55, 'bestNtreeLimit': 56, 'theScore': 0.99594}
{
    "train": {
        "error": [
            0.002752,
            0.002511,
            0.002381,
            0.002368,
            0.002379,
            0.002298,
            0.002316,
            0.002324,
            0.002342,
            0.002355,
            0.002332,
            0.002302,
            0.002302,
            0.002306,
            0.002288,
            0.002289,
            0.002279,
            0.002254,
            0.002234,
            0.00222,
            0.002204,
            0.002206,
            0.002203,
            0.002193,
            0.002201,
            0.002199,
            0.002197,
            0.002181,
            0.002176,
            0.002159,
            0.002155,
            0.002156,
            0.002146,
            0.002129,
            0.002121,
            0.002112,
            0.002109,
            0.002105,
            0.002093,
            0.002085,
            0.002081,
            0.002069,
            0.002063,
            0.002057,
            0.002046,
            0.002044,
            0.00204,
            0.002032,
            0.002024,
            0.002022,
            0.002015,
            0.002009,
            0.002002,
            0.001999,
            0.001995,
            0.001991,
            0.001989,
            0.001987,
            0.00198,
            0.001972,
            0.001962,
            0.001955,
            0.001952,
            0.001949,
            0.00194,
            0.001931,
            0.001927,
            0.001923,
            0.001917,
            0.001908,
            0.001902,
            0.001894,
            0.00189,
            0.001887,
            0.001885
        ]
    },
    "val": {
        "error": [
            0.004223,
            0.004231,
            0.004258,
            0.004267,
            0.004324,
            0.00426,
            0.004324,
            0.004352,
            0.004325,
            0.004341,
            0.00432,
            0.004282,
            0.004275,
            0.004288,
            0.004238,
            0.004245,
            0.004248,
            0.004204,
            0.004162,
            0.004148,
            0.004126,
            0.004133,
            0.00412,
            0.004107,
            0.004106,
            0.004114,
            0.004089,
            0.004091,
            0.004112,
            0.004101,
            0.004101,
            0.0041,
            0.004089,
            0.004081,
            0.00409,
            0.004076,
            0.004067,
            0.004079,
            0.004087,
            0.00407,
            0.004078,
            0.004086,
            0.004085,
            0.004074,
            0.004075,
            0.004068,
            0.004075,
            0.004078,
            0.004076,
            0.004085,
            0.004065,
            0.004063,
            0.004083,
            0.00408,
            0.004066,
            0.00406,
            0.004064,
            0.004066,
            0.00407,
            0.004094,
            0.004093,
            0.004089,
            0.004084,
            0.00408,
            0.004078,
            0.004077,
            0.004081,
            0.004078,
            0.004085,
            0.004083,
            0.004082,
            0.004087,
            0.004083,
            0.004077,
            0.004081
        ]
    }
}